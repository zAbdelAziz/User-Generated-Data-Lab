{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*UE Learning from User-generated Data, CP MMS, JKU Linz 2023*\n",
    "# Exercise 5: Popularity bias evaluation\n",
    "\n",
    "In this exercise we evaluate popularity bias of three different RecSys we already implemented. Note that here we utilize only one possible approach to evaluation of popularity bias from the user perspective. Refer to the slides and the recording for more details.\n",
    "\n",
    "This time recomendations for each algorithm are already provided in three separate files (can be found on the main page).\n",
    "\n",
    "Evaluating popularity bias through the mismatch (miscalibration) between popularity distributions over users' listening histories and their respective recommendations requires knowing how popular each item of the dataset is. Please use the new version of the lfm-tiny dataset where popularity categories (`popularity_bins`) from `0` (LowPop) to `2` (HighPop) have been already assigned. You will not need the test set for this exercise.\n",
    "\n",
    "Make sure to rename the notebook according to the convention:\n",
    "\n",
    "LUD23_ex05_k<font color='red'><Matr. Number\\></font>_<font color='red'><Surname-Name\\></font>.ipynb\n",
    "\n",
    "for example:\n",
    "\n",
    "LUD23_ex05_k000007_Bond_James.ipynb\n",
    "\n",
    "## Implementation\n",
    "In this exercise, as before, you are reqired to write a number of functions. Only implemented functions are graded. Insert your implementations into the templates provided. Please don't change the templates even if they are not pretty. Don't forget to test your implementation for correctness and efficiency. **Make sure to try your implementations on toy examples and sanity checks.**\n",
    "\n",
    "Please **only use libraries already imported in the notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rec import inter_matr_implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1\n",
    "\n",
    "Implement Kullback–Leibler divergence (KL) and Jensen–Shannon divergence (JSD).\n",
    "\n",
    "#### in KL\n",
    "Make sure to\n",
    "* use the logarithm with base 2\n",
    "* add `eps` to both `P` and `Q` distributions\n",
    "* **normalize** (convert to probability) the distributions again after you have added `eps`\n",
    "\n",
    "#### for JSD\n",
    "* feel free to call your implementation of KL from it\n",
    "* refer to the recording and slides for a recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def KL(P: np.ndarray, Q: np.ndarray, eps: float = 1e-14):\n",
    "    '''\n",
    "    P - np.ndarray, probability distribution\n",
    "    Q - np.ndarray, probability distribution\n",
    "    eps - float, margin added to both distributions to avoid division by zero errors\n",
    "    returns - float, divergence of distributions P,Q\n",
    "    '''\n",
    "\n",
    "    kl = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION\n",
    "    \n",
    "    # Add epsilon to avoid division by zero errors\n",
    "    P = P + eps\n",
    "    Q = Q + eps\n",
    "\n",
    "    # Normalize the distributions\n",
    "    P = P / np.sum(P)\n",
    "    Q = Q / np.sum(Q)\n",
    "\n",
    "    # Calculate KL divergence\n",
    "    kl = np.sum(P * np.log2(P / Q))\n",
    "    \n",
    "    # Convert numpy to native python scalar [For Assertion Only]\n",
    "    kl = kl.item()\n",
    "    return kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check if you handle zeros correctly (use \"eps\" parameter)\n",
    "P = np.array([0.3, 0.6, 0.1])\n",
    "Q = np.array([0.4, 0.6, 0.0])\n",
    "\n",
    "assert type(KL(P, Q)) == float\n",
    "assert np.isclose(KL(P, Q), 4.193995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def JSD(P: np.ndarray, Q: np.ndarray, eps: float = 1e-14):\n",
    "    '''\n",
    "    P - np.ndarray, probability distribution\n",
    "    Q - np.ndarray, probability distribution\n",
    "    eps - float, margin added to both distributions to avoid division by zero errors, parameter for KL\n",
    "    returns - float, divergence of distributions P,Q\n",
    "    '''\n",
    "\n",
    "    jsd = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION\n",
    "    # Calculate average distribution\n",
    "    M = 0.5 * (P + Q)\n",
    "\n",
    "    # Calculate JSD\n",
    "    jsd = 0.5 * (KL(P, M, eps) + KL(Q, M, eps))\n",
    "    \n",
    "    # Convert numpy to native python scalar [For Assertion Only]\n",
    "    jsd = jsd\n",
    "    return jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check if you handle zeros correctly (use \"eps\" parameter)\n",
    "P = np.array([0.3, 0.6, 0.1])\n",
    "Q = np.array([0.4, 0.6, 0.0])\n",
    "\n",
    "assert type(JSD(P, Q)) == float\n",
    "assert np.isclose(JSD(P, Q), 0.055170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# KL divergence compares a target distribution to a reference distribution and is NOT symmetric\n",
    "# JS divergence is symmetric -  you can exchange P and Q and get the same results\n",
    "# the following asserts check this behaviour\n",
    "P = np.array([0.3, 0.6, 0.1])\n",
    "Q = np.array([0.2, 0.3, 0.5])\n",
    "\n",
    "assert KL(P, Q) != KL(Q, P)\n",
    "assert JSD(P, Q) == JSD(Q, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 2\n",
    "\n",
    "Evaluating algorithms for popularity bias.\n",
    "First make sure all the data is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read(dataset, file):\n",
    "    return pd.read_csv(dataset + '/' + dataset + '.' + file, sep='\\t')\n",
    "\n",
    "\n",
    "items = read(\"lfm-tiny\", 'item')\n",
    "users = read(\"lfm-tiny\", 'user')\n",
    "train_inters = read(\"lfm-tiny\", 'inter_train')\n",
    "\n",
    "train_inter_matrix = inter_matr_implicit(users=users, items=items, interactions=train_inters, dataset_name=\"lfm-tiny\")\n",
    "\n",
    "# Information about item popularity: 0 - LowPop, 2 - HighPop\n",
    "item_pop_bins = items[\"popularity_bins\"].to_numpy()\n",
    "# Train set - users' listening history!\n",
    "train_interaction_matrix = train_inter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"item_pop_bins\": item_pop_bins,\n",
    "    \"user_histories\": train_interaction_matrix,\n",
    "    \"recommenders\": {}  # here you can access the recommendations for every algorithm\n",
    "}\n",
    "\n",
    "recommendations = {\"recommenders\": {\n",
    "    \"SVD\": {\n",
    "        \"recommendations\": np.array([])\n",
    "    },\n",
    "    \"ItemKNN\": {\n",
    "        \"recommendations\": np.array([])\n",
    "    },\n",
    "    \"TopPop\": {\n",
    "        \"recommendations\": np.array([])\n",
    "    },\n",
    "}}\n",
    "\n",
    "# Loading predictions\n",
    "for recommender in recommendations[\"recommenders\"].keys():\n",
    "    recommendations[\"recommenders\"][recommender][\"recommendations\"] = np.load(f\"recommendations/{recommender}.npy\")\n",
    "\n",
    "config.update(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `evaluate_jsd` and then call it from `evaluate_algorithms`. Do not use any global variables.\n",
    "For each user construct the two popularity distributions (from history and recommendations), normalize them, push through JSD and return the overall mean over users as the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_jsd(recommendations, user_histories, item_pop_bins):\n",
    "    '''\n",
    "    recommendations - np.ndarray, 2d array containing indices of recommended items for every user\n",
    "    user_histories - list of np.ndarray, containing the item indices of user interactions from the training set\n",
    "    item_pop_bins - np.ndarray, 1d array that contains the popularity bin number of an item at the respective index\n",
    "    returns - float, mean of jensen-shannon divergence over all users\n",
    "    '''\n",
    "\n",
    "    mean_jsd = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION\n",
    "    num_users = len(recommendations)\n",
    "    jsd_values = []\n",
    "\n",
    "    for user_id in range(num_users):\n",
    "        recommendation_indices = recommendations[user_id]\n",
    "        history_indices = user_histories[user_id]\n",
    "        \n",
    "        # Construct popularity distributions from history and recommendations\n",
    "        history_popularity = np.bincount(item_pop_bins[history_indices], minlength=len(item_pop_bins))\n",
    "        recommendation_popularity = np.bincount(item_pop_bins[recommendation_indices], minlength=len(item_pop_bins))\n",
    "\n",
    "        # Normalize the distributions\n",
    "        history_popularity = history_popularity / np.sum(history_popularity)\n",
    "        recommendation_popularity = recommendation_popularity / np.sum(recommendation_popularity)\n",
    "\n",
    "        # Calculate JSD\n",
    "        jsd = JSD(history_popularity, recommendation_popularity)\n",
    "        jsd_values.append(jsd)\n",
    "\n",
    "    # Calculate the mean JSD over all users\n",
    "    mean_jsd = np.mean(jsd_values)\n",
    "    return mean_jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_histories = [np.array([5, 6]), np.array([7, 8, 9])]\n",
    "item_pop_bins = np.array([0, 0, 0, 0, 0, 0, 0, 1, 2, 2])\n",
    "recommendations = np.array([[0, 1, 8, 3, 4], [0, 1, 2, 3, 4]])\n",
    "\n",
    "jsd = evaluate_jsd(recommendations, user_histories, item_pop_bins)\n",
    "\n",
    "assert np.isclose(jsd, 0.554015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`evaluate_algorithms` takes the config as an input and evaluates popularity bias of all algorithms listed in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_algorithms(config):\n",
    "    '''\n",
    "    config - dictionary, provides the run config for the evaluation, use the already provided \"config\"\n",
    "    returns - dictionary, result dictionary as provided within the function\n",
    "    '''\n",
    "    result = {\n",
    "        \"recommenders\": {# jsd per algorithm stored here\n",
    "            \"SVD\": {\n",
    "                \"jsd\": 0\n",
    "            },\n",
    "            \"ItemKNN\": {\n",
    "                \"jsd\": 0\n",
    "            },\n",
    "            \"TopPop\": {\n",
    "                \"jsd\": 0\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # TODO: YOUR IMPLEMENTATION\n",
    "    user_histories = config[\"user_histories\"]\n",
    "    item_pop_bins = config[\"item_pop_bins\"]\n",
    "        \n",
    "    for algorithm in result[\"recommenders\"]:\n",
    "        recommendations = config[\"recommenders\"][algorithm][\"recommendations\"]\n",
    "        mean_jsd = evaluate_jsd(recommendations, user_histories, item_pop_bins)\n",
    "\n",
    "        result[\"recommenders\"][algorithm][\"jsd\"] = mean_jsd\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = evaluate_algorithms(config)\n",
    "assert isinstance(result[\"recommenders\"][\"SVD\"][\"jsd\"], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recommenders': {'SVD': {'jsd': 0.6828240626375526}, 'ItemKNN': {'jsd': 0.5168217834320056}, 'TopPop': {'jsd': 0.9771289695391738}}}\n"
     ]
    }
   ],
   "source": [
    "# Investigate your results - which algorithm has the lowest bias/divergence?\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
